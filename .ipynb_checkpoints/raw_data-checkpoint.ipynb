{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = \"/Users/betashort/Downloads/16000_pcm_speeches/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jens_Stoltenberg',\n",
       " 'Benjamin_Netanyau',\n",
       " '.DS_Store',\n",
       " 'other',\n",
       " '_background_noise_',\n",
       " 'Julia_Gillard',\n",
       " 'Magaret_Tarcher',\n",
       " 'Nelson_Mandela',\n",
       " 'tf_Wav_reader.py']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_label = {'Jens_Stoltenberg' : 0,\n",
    "                 'Benjamin_Netanyau': 1,                 \n",
    "                 'Julia_Gillard' : 2,\n",
    "                 'Magaret_Tarcher' : 3,\n",
    "                 'Nelson_Mandela' : 4,\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0~1499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Audio_Datasets(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, file_label_list):\n",
    "        self.path = file_label_list\n",
    "        self.sr = 22000\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data, _ = librosa.load(self.path[idx][0])\n",
    "        data = data[:self.sr]\n",
    "        data = data.reshape(1, self.sr)\n",
    "        label = np.array(self.path[idx][1])\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_file_label(speaker_label):\n",
    "    file_label_list = []\n",
    "    file_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for label in speaker_label.keys():\n",
    "        n_file = len(glob.glob(os.path.join(path_name, list(speaker_label.keys())[0])+\"/*.wav\"))\n",
    "        \n",
    "        for i in range(n_file):\n",
    "            \n",
    "            file_label_list.append((os.path.join(path_name, label, f\"{i}.wav\"), speaker_label[label]))\n",
    "            \n",
    "            file_list.append(os.path.join(path_name, label, f\"{i}.wav\"))\n",
    "            label_list.append(speaker_label[label])\n",
    "            \n",
    "    return file_label_list, file_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_label_list, file_list, label_list = Read_file_label(speaker_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Audio_Datasets(file_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(file_list, label_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAEICAYAAAC59WLsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAevUlEQVR4nO3df7DddX3n8edrCVArLqAEG5PQ4Dbrik4FNot0mW1Z0QpoDZ3FDnQXqE2btuKqqzMtdneL1XVLZ1ux7rY4KKyhiyCLtqYulqb8GMfZBQ2ICEZLRAqRlKTyS2vFBt/7x/mEXG7OTW7uvTnnc2+ej5kz9/v9fD/nnPf5Es5nXt8fn5OqQpIkSZKknvyjcRcgSZIkSdJkhlVJkiRJUncMq5IkSZKk7hhWJUmSJEndMaxKkiRJkrpjWJUkSZIkdcewKi1AST6U5D+Puw5Jkg5USVYkqSSL2vpnklwwnb6SBgyrUoeSPJDk1TN9flX9alW9dy5rkiTpQJPkxiTvGdK+Osnf7Eu4rKozqmrd3FYoLWyGVWme8airJEkj81HgvCSZ1H4ecHVV7Rh9SdKBw7AqdSbJHwPHAH+W5DtJfr1dGrQmyYPAza3f/25HdZ9I8tkkL5vwGh9N8l/a8qlJtiR5Z5JtSbYmedNYPpwkSfPLnwLPB/7VzoYkRwKvB65K8rokX0zyZJKHkrx7qhdKcmuSX2rLByX5vSR/m+R+4HX792NI85NhVepMVZ0HPAj8TFUdBlzXNv0U8FLgtW39M8BK4GjgTuDqPbzsjwCHA0uBNcAftsFWkiRNoar+nsE4fP6E5p8DvlpVXwL+rm07gkHg/LUkZ03jpX+ZQeA9AVgFnD2XdUsLhWFVmj/eXVV/1wZOqurKqvp2VT0FvBt4RZLDp3juPwDvqap/qKobgO8ALxlJ1ZIkzW/rgDcmeU5bP7+1UVW3VtWXq+oHVXU3cA2Dg8t783PAB6rqoap6FPid/VG4NN8ZVqX546GdC+3yoUuSfD3Jk8ADbdNRUzz3W5Puq/kucNj+KVOSpIWjqj4HbAdWJ3kx8C+AjwEkeWWSW5JsT/IE8KtMPRZP9CImjOvAX89x2dKCYFiV+lR7aft5YDXwagaX965o7ZMngJAkSbN3FYMzqucBf1FVj7T2jwHrgeVVdTjwIaY3Fm8Flk9YP2YOa5UWDMOq1KdHgBfvYfvzgKeAbwE/DPzXURQlSdIB6ioGB4h/mXYJcPM84NGq+l6SkxgcTJ6O64C3JlnW5pC4aE6rlRYIw6rUp98B/lOSxxk+6cJVDC4Z+ibwFeC2EdYmSdIBpaoeAP4v8FwGZ1J3ejPwniTfBn6LXZMi7s2HgRuBLzGYJPGTc1astICkatjVhpIkSZIkjY9nViVJkiRJ3TGsSpIkSZK6Y1iVJEmSJHXHsCpJkiRJ6s6icRewJ0cddVStWLFi3GVIkhaIO+6442+ravG465jPHJslSXNpT2Nz12F1xYoVbNy4cdxlSJIWiCR/Pe4a5jvHZknSXNrT2OxlwJIkSZKk7hhWJUmSJEndMaxKkiRJkrpjWJUkSZIkdcewKkmSJEnqjmFVkiRJktQdw6okSZIkqTuGVUmSJElSdwyrkiRJkqTuLNpbhyRXAq8HtlXVy1vbfwN+Bvg+8HXgTVX1eNv2LmAN8DTw1qq6sbWfDvwBcBDwkaq6ZO4/jiRptlZc9H/GXcJuHrjkdeMuQZL2id+l0uxN58zqR4HTJ7VtAF5eVT8O/BXwLoAkxwHnAC9rz/mjJAclOQj4Q+AM4Djg3NZXkiRJkqTd7PXMalV9NsmKSW1/MWH1NuDstrwauLaqngK+kWQzcFLbtrmq7gdIcm3r+5VZVb8PPLolSZIkSfPHXsPqNPwi8PG2vJRBeN1pS2sDeGhS+yuHvViStcBagGOOOWYOypOkAQ9aSZqP/O6SdKCa1QRLSf4jsAO4emfTkG61h/bdG6sur6pVVbVq8eLFsylPkiRJkjRPzfjMapILGEy8dFpV7QyeW4DlE7otAx5uy1O1S5IkSZL0LDMKq21m398Afqqqvjth03rgY0neD7wIWAl8nsGZ1ZVJjgW+yWASpp+fTeHaP7zUaH7yv5skSZIWmun8dM01wKnAUUm2ABczmP33UGBDEoDbqupXq+reJNcxmDhpB3BhVT3dXuctwI0Mfrrmyqq6dz98HkmSJEnSAjCd2YDPHdJ8xR76vw9435D2G4Ab9qk6SZIkSdIBaVYTLEmSpH4k+aEkn0/ypST3Jvnt1n5sktuT3Jfk40kOae2HtvXNbfuKcdYvSdJEhlVJkhaOp4BXVdUrgOOB05OcDPwucGlVrQQeA9a0/muAx6rqx4BLWz9JkrpgWJUkaYGoge+01YPbo4BXAde39nXAWW15dVunbT8tbTIKSZLGzbAqSdICkuSgJHcB24ANwNeBx6tqR+uyBVjalpcCDwG07U8ALxjymmuTbEyycfv27fv7I0iSBBhWJUlaUKrq6ao6nsFvmp8EvHRYt/Z32FnU2q2h6vKqWlVVqxYvXjx3xUqStAcz+p1VSZLUt6p6PMmtwMnAEUkWtbOny4CHW7ctwHJgS5JFwOHAo+OoV9KByd+K1554ZlWSpAUiyeIkR7Tl5wCvBjYBtwBnt24XAJ9qy+vbOm37zVW125lVSZLGwTOrkiQtHEuAdUkOYnBA+rqq+nSSrwDXJvkvwBfZ9XvpVwB/nGQzgzOq54yjaEmShjGsSpK0QFTV3cAJQ9rvZ3D/6uT27wFvHEFpkiTtM8OqJEkaC+9VkyTtifesSpIkSZK6Y1iVJEmSJHXHsCpJkiRJ6o5hVZIkSZLUHcOqJEmSJKk7hlVJkiRJUncMq5IkSZKk7vg7q5IkSZLUsQP1d6k9sypJkiRJ6o5hVZIkSZLUHcOqJEmSJKk7hlVJkiRJUncMq5IkSZKk7hhWJUmSJEndMaxKkiRJkrqz17Ca5Mok25LcM6Ht+Uk2JLmv/T2ytSfJB5NsTnJ3khMnPOeC1v++JBfsn48jSZIkSVoIpnNm9aPA6ZPaLgJuqqqVwE1tHeAMYGV7rAUug0G4BS4GXgmcBFy8M+BKkiRJkjTZXsNqVX0WeHRS82pgXVteB5w1of2qGrgNOCLJEuC1wIaqerSqHgM2sHsAliRJkiQJmPk9qy+sqq0A7e/RrX0p8NCEflta21Ttu0myNsnGJBu3b98+w/IkSZIkSfPZXE+wlCFttYf23RurLq+qVVW1avHixXNanCRJkiRpfphpWH2kXd5L+7uttW8Blk/otwx4eA/tkiRJkiTtZqZhdT2wc0bfC4BPTWg/v80KfDLwRLtM+Ebgp5Mc2SZW+unWJkmSJEnSbqbz0zXXAP8PeEmSLUnWAJcAr0lyH/Catg5wA3A/sBn4MPBmgKp6FHgv8IX2eE9rkyRJcyTJ8iS3JNmU5N4kb2vt707yzSR3tceZE57zrvaTc19L8trxVS9J0rMt2luHqjp3ik2nDelbwIVTvM6VwJX7VJ0kSdoXO4B3VtWdSZ4H3JFkQ9t2aVX93sTOSY4DzgFeBrwI+Msk/7Sqnh5p1ZIkDTHXEyxJkqQxqaqtVXVnW/42sIkpZt9vVgPXVtVTVfUNBldGnbT/K5Ukae8Mq5IkLUBJVgAnALe3prckuTvJlW3+CNiHn5aTJGnUDKuSJC0wSQ4DPgG8vaqeBC4D/glwPLAV+P2dXYc8fbeflvM30CVJ42BYlSRpAUlyMIOgenVVfRKgqh6pqqer6gcMJkDceanvtH5azt9AlySNg2FVkqQFIkmAK4BNVfX+Ce1LJnT7WeCetrweOCfJoUmOBVYCnx9VvZIk7cleZwOWJEnzxinAecCXk9zV2n4TODfJ8Qwu8X0A+BWAqro3yXXAVxjMJHyhMwFLknphWJUkaYGoqs8x/D7UG/bwnPcB79tvRUmSNENeBixJkiRJ6o5hVZIkSZLUHcOqJEmSJKk7hlVJkiRJUncMq5IkSZKk7hhWJUmSJEndMaxKkiRJkrpjWJUkSZIkdcewKkmSJEnqjmFVkiRJktQdw6okSZIkqTuGVUmSJElSdwyrkiRJkqTuGFYlSZIkSd0xrEqSJEmSumNYlSRJkiR1x7AqSZIkSeqOYVWSJEmS1J1ZhdUk/yHJvUnuSXJNkh9KcmyS25Pcl+TjSQ5pfQ9t65vb9hVz8QEkSZIkSQvPjMNqkqXAW4FVVfVy4CDgHOB3gUuraiXwGLCmPWUN8FhV/RhwaesnSZIkSdJuZnsZ8CLgOUkWAT8MbAVeBVzftq8DzmrLq9s6bftpSTLL95ckSZIkLUAzDqtV9U3g94AHGYTUJ4A7gMerakfrtgVY2paXAg+15+5o/V8w+XWTrE2yMcnG7du3z7Q8SZIkSdI8NpvLgI9kcLb0WOBFwHOBM4Z0rZ1P2cO2XQ1Vl1fVqqpatXjx4pmWJ0mSJEmax2ZzGfCrgW9U1faq+gfgk8C/BI5olwUDLAMebstbgOUAbfvhwKOzeH9JkiRJ0gI1m7D6IHBykh9u956eBnwFuAU4u/W5APhUW17f1mnbb66q3c6sSpKkmUmyPMktSTa12frf1tqfn2RDm6l/Q7s6igx8sM3Uf3eSE8f7CSRJ2mU296zezmCipDuBL7fXuhz4DeAdSTYzuCf1ivaUK4AXtPZ3ABfNom5JkrS7HcA7q+qlwMnAhUmOYzDm3tRm6r+JXWPwGcDK9lgLXDb6kiVJGm7R3rtMraouBi6e1Hw/cNKQvt8D3jib95MkSVOrqq0MJj2kqr6dZBODCQ5XA6e2buuAWxkcXF4NXNWudLotyRFJlrTXkSRprGb70zWSJKlDSVYAJwC3Ay/cGUDb36Nbt2dm6m8mzuI/8bWcqV+SNHKGVUmSFpgkhwGfAN5eVU/uqeuQNmfqlyR1wbAqSdICkuRgBkH16qr6ZGt+JMmStn0JsK21PzNTfzNxFn9JksbKsCpJ0gLRZue/AthUVe+fsGnijPyTZ+o/v80KfDLwhPerSpJ6MasJliRJUldOAc4Dvpzkrtb2m8AlwHVJ1jD46bmdEx7eAJwJbAa+C7xptOVKkjQ1w6okSQtEVX2O4fehwuD30Cf3L+DC/VqUJEkz5GXAkiRJkqTuGFYlSZIkSd0xrEqSJEmSumNYlSRJkiR1x7AqSZIkSeqOYVWSJEmS1B3DqiRJkiSpO4ZVSZIkSVJ3DKuSJEmSpO4YViVJkiRJ3TGsSpIkSZK6Y1iVJEmSJHXHsCpJkiRJ6o5hVZIkSZLUHcOqJEmSJKk7hlVJkiRJUncMq5IkSZKk7hhWJUmSJEndMaxKkiRJkrozq7Ca5Igk1yf5apJNSX4iyfOTbEhyX/t7ZOubJB9MsjnJ3UlOnJuPIEmSJElaaGZ7ZvUPgD+vqn8GvALYBFwE3FRVK4Gb2jrAGcDK9lgLXDbL95YkSZIkLVAzDqtJ/jHwk8AVAFX1/ap6HFgNrGvd1gFnteXVwFU1cBtwRJIlM65ckiRJkrRgzebM6ouB7cD/TPLFJB9J8lzghVW1FaD9Pbr1Xwo8NOH5W1rbsyRZm2Rjko3bt2+fRXmSJEmSpPlqNmF1EXAicFlVnQD8Hbsu+R0mQ9pqt4aqy6tqVVWtWrx48SzKkyTpwJPkyiTbktwzoe3dSb6Z5K72OHPCtne1+SS+luS146lakqTdzSasbgG2VNXtbf16BuH1kZ2X97a/2yb0Xz7h+cuAh2fx/pIkaXcfBU4f0n5pVR3fHjcAJDkOOAd4WXvOHyU5aGSVSpK0BzMOq1X1N8BDSV7Smk4DvgKsBy5obRcAn2rL64Hz26zAJwNP7LxcWJIkzY2q+izw6DS7rwauraqnquobwGbgpP1WnCRJ+2DRLJ//74GrkxwC3A+8iUEAvi7JGuBB4I2t7w3AmQwGwu+2vpIkaTTekuR8YCPwzqp6jMHcEbdN6DPlfBIMZvLnmGOOGUGpkiTNMqxW1V3AqiGbThvSt4ALZ/N+kiRpRi4D3stgroj3Ar8P/CL7MJ8EcDnAqlWrdtsuSdL+MNvfWZUkSZ2rqkeq6umq+gHwYXZd6ut8EpKkbhlWJUla4Cb9rvnPAjtnCl4PnJPk0CTHAiuBz4+6PkmShpntPauSJKkjSa4BTgWOSrIFuBg4NcnxDC7xfQD4FYCqujfJdQwmSNwBXFhVT4+jbkmSJjOsSpK0gFTVuUOar9hD//cB79t/FUmSNDNeBixJkiRJ6o5hVZIkSZLUHcOqJEmSJKk7hlVJkiRJUncMq5IkSZKk7hhWJUmSJEndMaxKkiRJkrpjWJUkSZIkdcewKkmSJEnqjmFVkiRJktQdw6okSZIkqTuGVUmSJElSdwyrkiRJkqTuGFYlSZIkSd0xrEqSJEmSumNYlSRJkiR1x7AqSZIkSeqOYVWSJEmS1B3DqiRJkiSpO4ZVSZIkSVJ3DKuSJEmSpO7MOqwmOSjJF5N8uq0fm+T2JPcl+XiSQ1r7oW19c9u+YrbvLUmSJElamObizOrbgE0T1n8XuLSqVgKPAWta+xrgsar6MeDS1k+SJEmSpN3MKqwmWQa8DvhIWw/wKuD61mUdcFZbXt3WadtPa/0lSZIkSXqW2Z5Z/QDw68AP2voLgMerakdb3wIsbctLgYcA2vYnWv9nSbI2ycYkG7dv3z7L8iRJOrAkuTLJtiT3TGh7fpIN7RadDUmObO1J8sF2i87dSU4cX+WSJD3bjMNqktcD26rqjonNQ7rWNLbtaqi6vKpWVdWqxYsXz7Q8SZIOVB8FTp/UdhFwU7tF56a2DnAGsLI91gKXjahGSZL2ajZnVk8B3pDkAeBaBpf/fgA4Ismi1mcZ8HBb3gIsB2jbDwcencX7S5KkSarqs+w+vk68FWfyLTpX1cBtDMbwJaOpVJKkPZtxWK2qd1XVsqpaAZwD3FxV/xa4BTi7dbsA+FRbXt/WadtvrqrdzqxKkqQ598Kq2grQ/h7d2p+5RaeZePvOM7xFR5I0Dvvjd1Z/A3hHks0M7km9orVfAbygtb+DXZcgSZKk8fAWHUlStxbtvcveVdWtwK1t+X7gpCF9vge8cS7eT5Ik7ZNHkiypqq3tMt9trf2ZW3SaibfvSJI0VvvjzKokSerLxFtxJt+ic36bFfhk4ImdlwtLkjRuc3JmVZIk9SHJNcCpwFFJtgAXA5cA1yVZAzzIriudbgDOBDYD3wXeNPKCJUmagmFVkqQFpKrOnWLTaUP6FnDh/q1IkqSZ8TJgSZIkSVJ3DKuSJEmSpO4YViVJkiRJ3TGsSpIkSZK6Y1iVJEmSJHXHsCpJkiRJ6o5hVZIkSZLUHcOqJEmSJKk7hlVJkiRJUncMq5IkSZKk7hhWJUmSJEndMaxKkiRJkrpjWJUkSZIkdcewKkmSJEnqjmFVkiRJktQdw6okSZIkqTuGVUmSJElSdwyrkiRJkqTuGFYlSZIkSd0xrEqSJEmSumNYlSRJkiR1x7AqSZIkSerOjMNqkuVJbkmyKcm9Sd7W2p+fZEOS+9rfI1t7knwwyeYkdyc5ca4+hCRJkiRpYZnNmdUdwDur6qXAycCFSY4DLgJuqqqVwE1tHeAMYGV7rAUum8V7S5KkfZTkgSRfTnJXko2tbehBZkmSxm3GYbWqtlbVnW3528AmYCmwGljXuq0DzmrLq4GrauA24IgkS2ZcuSRJmol/XVXHV9Wqtj7VQWZJksZqTu5ZTbICOAG4HXhhVW2FQaAFjm7dlgIPTXjaltY2+bXWJtmYZOP27dvnojxJkjS1qQ4yS5I0VrMOq0kOAz4BvL2qntxT1yFttVtD1eVVtaqqVi1evHi25UmSpF0K+IskdyRZ29qmOsj8DA8kS5LGYdFsnpzkYAZB9eqq+mRrfiTJkqra2i7z3dbatwDLJzx9GfDwbN5fkiTtk1Oq6uEkRwMbknx1Ok+qqsuBywFWrVq124FmSZL2h9nMBhzgCmBTVb1/wqb1wAVt+QLgUxPaz2+zAp8MPLHzSK4kSdr/qurh9ncb8CfASbSDzACTDjJLkjRWs7kM+BTgPOBVbVbBu5KcCVwCvCbJfcBr2jrADcD9wGbgw8CbZ/HekiRpHyR5bpLn7VwGfhq4h6kPMkuSNFYzvgy4qj7H8PtQAU4b0r+AC2f6fpIkaVZeCPzJ4MIoFgEfq6o/T/IF4Loka4AHgTeOsUZJkp4xq3tWJUnS/FBV9wOvGNL+LYYcZJYkadzm5KdrJEmSJEmaS4ZVSZIkSVJ3DKuSJEmSpO4YViVJkiRJ3TGsSpIkSZK6Y1iVJEmSJHXHsCpJkiRJ6o5hVZIkSZLUHcOqJEmSJKk7hlVJkiRJUncMq5IkSZKk7hhWJUmSJEndMaxKkiRJkrpjWJUkSZIkdcewKkmSJEnqjmFVkiRJktQdw6okSZIkqTuGVUmSJElSdwyrkiRJkqTuGFYlSZIkSd0xrEqSJEmSumNYlSRJkiR1x7AqSZIkSeqOYVWSJEmS1J2Rh9Ukpyf5WpLNSS4a9ftLkqRnc2yWJPVopGE1yUHAHwJnAMcB5yY5bpQ1SJKkXRybJUm9GvWZ1ZOAzVV1f1V9H7gWWD3iGiRJ0i6OzZKkLqWqRvdmydnA6VX1S239POCVVfWWCX3WAmvb6kuAr83R2x8F/O0cvdYoWfdoWfdozde6Yf7WfqDX/aNVtXgOXmfBcGyeEeseLeserflaN8zf2g/0uqccmxfNwYvviwxpe1ZarqrLgcvn/I2TjVW1aq5fd3+z7tGy7tGar3XD/K3dujWEY/M+su7Rsu7Rmq91w/yt3bqnNurLgLcAyyesLwMeHnENkiRpF8dmSVKXRh1WvwCsTHJskkOAc4D1I65BkiTt4tgsSerSSC8DrqodSd4C3AgcBFxZVfeO6O3n/PKlEbHu0bLu0ZqvdcP8rd269SyOzTNi3aNl3aM1X+uG+Vu7dU9hpBMsSZIkSZI0HaO+DFiSJEmSpL0yrEqSJEmSurPgwmqS05N8LcnmJBcN2X5oko+37bcnWTH6Knc3jbp/Icn2JHe1xy+No85JNV2ZZFuSe6bYniQfbJ/p7iQnjrrGYaZR96lJnpiwr39r1DUOk2R5kluSbEpyb5K3DenT3T6fZt3d7fMkP5Tk80m+1Or+7SF9ev0+mU7t3X2nACQ5KMkXk3x6yLYu97f2zrF5dBybR8uxebTm69g8n8dlGPPYXFUL5sFgYoivAy8GDgG+BBw3qc+bgQ+15XOAj8+Tun8B+B/jrnVSTT8JnAjcM8X2M4HPMPgNv5OB28dd8zTrPhX49LjrHFLXEuDEtvw84K+G/Dvpbp9Ps+7u9nnbh4e15YOB24GTJ/Xp7vtkH2rv7jul1fUO4GPD/j30ur997PW/qWPzaOt2bB5t3Y7No617Xo7N83lcbrWNbWxeaGdWTwI2V9X9VfV94Fpg9aQ+q4F1bfl64LQkw34QfZSmU3d3quqzwKN76LIauKoGbgOOSLJkNNVNbRp1d6mqtlbVnW3528AmYOmkbt3t82nW3Z22D7/TVg9uj8kz0vX4fTLd2ruTZBnwOuAjU3Tpcn9rrxybR8ixebQcm0drvo7N83VchvGPzQstrC4FHpqwvoXd/8d7pk9V7QCeAF4wkuqmNp26Af5Nu3zk+iTLh2zvzXQ/V49+ol2q8ZkkLxt3MZO1SyxOYHBkbqKu9/ke6oYO93m77OUuYBuwoaqm3N8dfZ8A06od+vtO+QDw68APptje7f7WHjk296XrcWIvuhsnJnJsHo35OjbP03EZxjw2L7SwOizFTz5qMZ0+ozadmv4MWFFVPw78JbuOYPSsx309HXcCP1pVrwD+O/CnY67nWZIcBnwCeHtVPTl585CndLHP91J3l/u8qp6uquOBZcBJSV4+qUu3+3satXf1nZLk9cC2qrpjT92GtHWxv7VHjs196XFfT0eX48ROjs2jM1/H5vk2LkMfY/NCC6tbgIlHIZYBD0/VJ8ki4HDGf9nJXuuuqm9V1VNt9cPAPx9RbbMxnf8e3amqJ3deqlFVNwAHJzlqzGUBkORgBoPK1VX1ySFdutzne6u7530OUFWPA7cCp0/a1OP3ybNMVXuH3ymnAG9I8gCDyy1fleR/TerT/f7WUI7NfelynNibnscJx+bxmK9j8zwal6GDsXmhhdUvACuTHJvkEAY3+a6f1Gc9cEFbPhu4uarGfbRlr3VPurfhDQzuLejdeuD8DJwMPFFVW8dd1N4k+ZGd19onOYnB/yffGm9Vg9kEgSuATVX1/im6dbfPp1N3j/s8yeIkR7Tl5wCvBr46qVuP3yfTqr2375SqeldVLauqFQy+A2+uqn83qVuX+1t75djcl+7GienocZxotTg2j9B8HZvn47gMfYzNi+bqhXpQVTuSvAW4kcEsfldW1b1J3gNsrKr1DP7H/OMkmxmk/nPGV/HANOt+a5I3ADsY1P0LYyu4SXINg5nijkqyBbiYwQ3jVNWHgBsYzIC3Gfgu8KbxVPps06j7bODXkuwA/h44Z9xfcs0pwHnAl9s9DwC/CRwDXe/z6dTd4z5fAqxLchCDAfq6qvp0798nzXRq7+47ZZh5sr+1B47No+XYPHKOzaM1X8fmBTMuw2jH5oz/35wkSZIkSc+20C4DliRJkiQtAIZVSZIkSVJ3DKuSJEmSpO4YViVJkiRJ3TGsSpIkSZK6Y1iVJEmSJHXHsCpJkiRJ6s7/B+tAlilhxj2mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train)\n",
    "plt.title(\"train\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y_valid)\n",
    "plt.title(\"Valid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [(X_train[idx], y_train[idx]) for idx in range(len(X_train))]\n",
    "valid = [(X_valid[idx], y_valid[idx]) for idx in range(len(X_valid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(Audio_Datasets(train), batch_size=120)\n",
    "valid_loader = torch.utils.data.DataLoader(Audio_Datasets(valid), batch_size=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1D,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(1, 8, kernel_size=10, stride=1),\n",
    "                                   nn.BatchNorm1d(8),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(kernel_size=10, stride=2),\n",
    "                                  )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(8, 32, kernel_size=100, stride=1),\n",
    "                                   nn.BatchNorm1d(32),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(kernel_size=100, stride=2),\n",
    "                                  )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(32, 64, kernel_size=300, stride=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(kernel_size=300, stride=2),\n",
    "                                  )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(nn.Conv1d(64, 128, kernel_size=500, stride=1),\n",
    "                                   nn.BatchNorm1d(128),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(kernel_size=500, stride=2),\n",
    "                                  )\n",
    "        \n",
    "        \n",
    "        self.dense = nn.Sequential(nn.Linear(89728, 512),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(),\n",
    "                                   nn.Linear(512,128),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(),\n",
    "                                   nn.Linear(128, 5),\n",
    "                                  )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def check_size(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 89728])\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Net1D().to(device)\n",
    "\n",
    "size_check = torch.FloatTensor(10, 1, 22000)\n",
    "print(model.check_size(size_check).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net1D().to(device)\n",
    "\n",
    "#weights = torch.tensor([1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==== 学習 ====\n",
    "def learning(train_loader, val_loader, num_epochs=10):\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valid_loss_list = []\n",
    "    valid_acc_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        \n",
    "        \n",
    "        #==== 学習 ====\n",
    "        net.train()\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            #==== deviceに渡す\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            #==== Optimizerの初期化 ====\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #==== forward processing ====\n",
    "            outputs = model(images)\n",
    "            \n",
    "            #==== Loss calcuration ====\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            #==== backward processing ====\n",
    "            loss.backward()\n",
    "            \n",
    "            #==== update optimizer ====\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += accuracy_score(labels.cpu().detach().clone().numpy(), \n",
    "                                        np.argmax(outputs.cpu().detach().clone().numpy(), axis=1),\n",
    "                                        )\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "        \n",
    "        #==== 検証 =====\n",
    "        net.eval()\n",
    "        \n",
    "        #重みを変えさせない\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                valid_acc += accuracy_score(labels.cpu().detach().clone().numpy(), \n",
    "                                            np.argmax(outputs.cpu().detach().clone().numpy(), axis=1),\n",
    "                                           )\n",
    "                \n",
    "        avg_valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "        avg_valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "        \n",
    "        print(f\"=====  epoch: {epoch+1} ===== \\\n",
    "        \\n train_loss: {avg_train_loss}, valid_loss: {avg_valid_loss} \\\n",
    "        \\n train_acc: {avg_train_acc}, valid_acc: {avg_valid_acc}\")\n",
    "        \n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "        valid_loss_list.append(avg_valid_loss)\n",
    "        valid_acc_list.append(avg_valid_acc)\n",
    "        \n",
    "    loss_list = [train_loss_list, valid_loss_list]\n",
    "    acc_list = [train_acc_list, valid_acc_list]\n",
    "    \n",
    "    return loss_list, acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-330-4cf1f4d6db34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-329-ecb595c7b05b>\u001b[0m in \u001b[0;36mlearning\u001b[0;34m(train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#==== backward processing ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#==== update optimizer ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/default/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/default/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list, acc_list = learning(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 0 4 3 1 0 4 1 1 3 1 2 2 0 1 3 1 3 2 3 1 2 0 1 3 1 0 4 0 0 3 2 2 4 1 1\n",
      " 3 0 1 2 0 0 4 4 2 4 3 1 0 3 1 0 4 1 3 4 1 0 1 2 0 4 4 0 3 4 3 0 2 4 2 1 1\n",
      " 1 2 1 4 0 2 1 4 3 0 3 3 0 1 2 0 3 3 4 1 2 4 4 3 2 3 3 3 1 0 2 2 4 0 4 3 1\n",
      " 4 2 3 1 1 1 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels.cpu().detach().clone().numpy())\n",
    "    outputs = model(images)\n",
    "    a = outputs.cpu().detach().clone().numpy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 2, 3, 3, 0, 2, 2, 0, 1, 2, 1, 2, 3, 1, 1, 1, 3, 1, 1,\n",
       "       2, 2, 0, 3, 0, 2, 3, 2, 2, 3, 2, 2, 2, 2, 1, 2, 0, 2, 0, 2, 1, 2,\n",
       "       2, 3, 1, 1, 0, 3, 3, 2, 0, 0, 1, 0, 2, 2, 3, 1, 0, 2, 1, 1, 1, 1,\n",
       "       3, 0, 2, 1, 4, 3, 3, 2, 2, 0, 2, 3, 2, 3, 2, 3, 1, 2, 3, 0, 0, 2,\n",
       "       0, 0, 4, 3, 1, 0, 2, 0, 3, 1, 2, 1, 3, 0, 0, 1, 3, 1, 0, 2, 1, 2,\n",
       "       2, 3, 3, 2, 3, 0, 0, 1, 3, 0])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
